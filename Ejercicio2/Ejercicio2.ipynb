{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Variational Autoencoder"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:45:47.376406Z",
     "start_time": "2024-06-23T17:45:46.005291Z"
    }
   },
   "source": [
    "from MLP_VAE import train, train_vae, Dense, Dense_vae, predict_with_layer_value, predict, reparameterize, vae_loss\n",
    "from activation_functions import Sigmoid\n",
    "from MLP_VAE import mse, mse_derivative\n",
    "from utils import fonts_to_bitmap, bitmap_as_matrix, get_config_params, train_different_architectures\n",
    "from plots import *\n",
    "from font import fontDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load fonts"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:45:47.389606Z",
     "start_time": "2024-06-23T17:45:47.379195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load fonts into list of bitmaps\n",
    "bitmap_dict = fonts_to_bitmap(fontDict)\n",
    "bitmap_list = list(bitmap_dict.values())  \n",
    "bitmap_labels = list(bitmap_dict.keys())\n",
    "\n",
    "X = np.reshape(bitmap_list,(len(bitmap_list), 35, 1))\n",
    "Y = np.array(bitmap_labels)\n",
    "\n",
    "#X = np.reshape(X,(len(X), 35))\n",
    "#X = X.astype(np.float32)\n",
    "print(X.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 35, 1)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:45:49.366235Z",
     "start_time": "2024-06-23T17:45:47.394109Z"
    }
   },
   "source": [
    "# Reshape each element of X to 7x5\n",
    "reshaped_X = np.reshape(X, (len(X), 7, 5))\n",
    "\n",
    "# Create a subplot with 1 row and as many columns as elements in X\n",
    "fig, axs = plt.subplots(1, len(X), figsize=(12, 6))\n",
    "\n",
    "# Plot each element of reshaped_X in a separate subplot\n",
    "for i in range(len(X)):\n",
    "    axs[i].imshow(reshaped_X[i], cmap='gray_r')\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(Y[i])  # Set the title to the corresponding label from Y\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 32 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:45:49.376854Z",
     "start_time": "2024-06-23T17:45:49.370122Z"
    }
   },
   "source": [
    "# Retrieve parameters from config file\n",
    "learning_rate, max_epochs, bias, beta1, beta2, epsilon, optimizer, activation = get_config_params('ejercicio2_config.json')\n",
    "\n",
    "mse_list = []"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:47:41.172428Z",
     "start_time": "2024-06-23T17:47:41.165743Z"
    }
   },
   "source": [
    "# The latent space is the output of \"layer 6\"\n",
    "def generate_vae():\n",
    "    encoder = [\n",
    "        Dense_vae(35, 20, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "        Dense_vae(20, 10, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "        Dense_vae(10, 2, optimizer_type=optimizer, learning_rate=learning_rate),  # mu layer\n",
    "        Dense_vae(10, 2, optimizer_type=optimizer, learning_rate=learning_rate, output_type='logvar'),  # logvar layer\n",
    "    ] \n",
    "\n",
    "    decoder = [\n",
    "        Dense_vae(2, 10, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "        Dense_vae(10, 20, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "        Dense_vae(20, 35, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "    ]\n",
    "\n",
    "    return encoder, decoder"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:47:52.793560Z",
     "start_time": "2024-06-23T17:47:52.786577Z"
    }
   },
   "source": [
    "wrong_dict = {}\n",
    "\n",
    "def is_same_pixel(pixel1, pixel2):\n",
    "    return round(pixel1) == round(pixel2)\n",
    "\n",
    "def compare_bitmaps(input_bitmap, output_bitmap, character, max_wrongs = 1):\n",
    "    wrongs = 0  \n",
    "    for i in range(7*5):\n",
    "        if not is_same_pixel(input_bitmap[i], output_bitmap[i]):\n",
    "            print(f\"Pixel {i} of '{character}' is different: {input_bitmap[i]} != {output_bitmap[i]}\")\n",
    "            wrongs += 1\n",
    "            if wrongs > max_wrongs:\n",
    "                return False\n",
    "            wrong_dict[character] = i\n",
    "    \n",
    "    return True"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:47:54.780377Z",
     "start_time": "2024-06-23T17:47:54.673892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "characters = list(bitmap_dict.keys())\n",
    "#print(characters)\n",
    "\n",
    "epochs = 5000\n",
    "#max_error = 0.02\n",
    "\n",
    "# Generate VAE\n",
    "encoder, decoder = generate_vae()\n",
    "\n",
    "# Train VAE\n",
    "losses = train_vae(encoder, decoder, X, epochs=epochs, verbose=True)\n",
    "\n",
    "# Print final loss\n",
    "print(f\"Final Loss: {losses[-1]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae input:  x_train shape:  (32, 35, 1) \n",
      "\n",
      "train_vae output shape:  (35, 1) \n",
      "\n",
      "Dense_vae.forward input shape: (35, 1)\n",
      "train_vae output shape:  (20, 1) \n",
      "\n",
      "train_vae output shape:  (20, 1) \n",
      "\n",
      "Dense_vae.forward input shape: (20, 1)\n",
      "train_vae output shape:  (10, 1) \n",
      "\n",
      "train_vae output shape:  (10, 1) \n",
      "\n",
      "Dense_vae.forward input shape: (10, 1)\n",
      "train_vae output shape:  (2, 1) \n",
      "\n",
      "Dense_vae.forward input shape: (2, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (2,10) and (2,1) not aligned: 10 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m encoder, decoder \u001B[38;5;241m=\u001B[39m generate_vae()\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Train VAE\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m losses \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_vae\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Print final loss\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlosses[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/sia-tp5/Ejercicio2/MLP_VAE.py:59\u001B[0m, in \u001B[0;36mtrain_vae\u001B[0;34m(encoder, decoder, x_train, epochs, verbose)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m encoder:\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_vae output shape: \u001B[39m\u001B[38;5;124m'\u001B[39m, output\u001B[38;5;241m.\u001B[39mshape, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 59\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer, Dense) \u001B[38;5;129;01mand\u001B[39;00m layer\u001B[38;5;241m.\u001B[39moutput_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmu\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     61\u001B[0m         mu \u001B[38;5;241m=\u001B[39m output\n",
      "File \u001B[0;32m~/PycharmProjects/sia-tp5/Ejercicio2/MLP_VAE.py:129\u001B[0m, in \u001B[0;36mDense_vae.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDense_vae.forward input shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)   \u001B[38;5;66;03m# debugging\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[0;32m--> 129\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\n",
      "\u001B[0;31mValueError\u001B[0m: shapes (2,10) and (2,1) not aligned: 10 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the VAE\n",
    "latent_spaces = []\n",
    "raw_latent_spaces = []\n",
    "input_matrix_list = []\n",
    "output_matrix_list = []\n",
    "correct = 0\n",
    "\n",
    "for c in range(len(characters)):\n",
    "    input_bitmap = []\n",
    "    output_bitmap = []\n",
    "\n",
    "    for i in range(len(X[c])):\n",
    "        input_bitmap.append(X[c][i][0])\n",
    "    input_matrix_list.append(bitmap_as_matrix(input_bitmap))\n",
    "\n",
    "    # Get the latent space representation\n",
    "    output = X[c]\n",
    "    for layer in encoder:\n",
    "        output = layer.forward(output)\n",
    "        if isinstance(layer, Dense) and layer.output_type == 'mu':\n",
    "            mu = output\n",
    "        elif isinstance(layer, Dense) and layer.output_type == 'logvar':\n",
    "            logvar = output\n",
    "    z = reparameterize(mu, logvar)\n",
    "    raw_latent_spaces.append(z)\n",
    "    latent_spaces.append((z[0][0], z[1][0]))\n",
    "\n",
    "    # Reconstruct from latent space\n",
    "    reconstructed = z\n",
    "    for layer in decoder:\n",
    "        reconstructed = layer.forward(reconstructed)\n",
    "\n",
    "    for output in reconstructed:\n",
    "        output_bitmap.append(output[0])\n",
    "\n",
    "    if not compare_bitmaps(input_bitmap, output_bitmap, characters[c]):\n",
    "        print(f\"Error in the reconstruction of character '{characters[c]}'\")\n",
    "    else:\n",
    "        correct += 1\n",
    "    \n",
    "    output_matrix_list.append(bitmap_as_matrix(output_bitmap))\n",
    "\n",
    "plot_bitmap_matrix_2(input_matrix_list, characters, \"Original Characters\")\n",
    "plot_bitmap_matrix_2(output_matrix_list, characters, \"Predicted Characters\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_bitmap_matrix_2(np.round(output_matrix_list), characters, \"Predicted Characters\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_latent_spaces(latent_spaces, characters)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example with random \"data\" of shape (35,1)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T17:49:25.567755Z",
     "start_time": "2024-06-23T17:49:25.545444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "characters = list(bitmap_dict.keys())\n",
    "\n",
    "def generate_vae(optimizer, learning_rate):\n",
    "    encoder = [\n",
    "        Dense_vae(35, 20, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "        Dense_vae(20, 10, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "        Dense_vae(10, 2, optimizer_type=optimizer, learning_rate=learning_rate),  # mu layer\n",
    "        Dense_vae(10, 2, optimizer_type=optimizer, learning_rate=learning_rate, output_type='logvar'),  # logvar layer\n",
    "    ]\n",
    "\n",
    "    decoder = [\n",
    "        Dense_vae(2, 10, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "        Dense_vae(10, 20, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "        Dense_vae(20, 35, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "        Sigmoid(),\n",
    "    ]\n",
    "\n",
    "    return encoder, decoder\n",
    "\n",
    "# Example usage:\n",
    "optimizer = 'ADAM'\n",
    "learning_rate = 0.001\n",
    "\n",
    "encoder, decoder = generate_vae(optimizer, learning_rate)\n",
    "\n",
    "# Example input\n",
    "x_train = np.random.rand(35, 1) # in our case the dimensions are (32, 35, 1) aka 32 letters (etc.) with dimension 35 (7x5)\n",
    "print('Pre-coding input', x_train, '\\n')\n",
    "#print('x=', x_train, '\\n') # debug\n",
    "\n",
    "# Forward pass through the encoder\n",
    "mu = encoder[4].forward(encoder[3].forward(encoder[2].forward(encoder[1].forward(encoder[0].forward(x_train)))))\n",
    "logvar = encoder[5].forward(encoder[3].forward(encoder[2].forward(encoder[1].forward(encoder[0].forward(x_train)))))\n",
    "print('mu=', mu,'logvar=',logvar,'\\n')  # debug\n",
    "\n",
    "# Reparameterize\n",
    "z = reparameterize(mu, logvar)\n",
    "print('z=',z,'\\n')  # debug\n",
    "\n",
    "# Forward pass through the decoder\n",
    "output_matrix_list = decoder[4].forward(decoder[3].forward(decoder[2].forward(decoder[1].forward(decoder[0].forward(z)))))\n",
    "print('Decoded output shape: ',output_matrix_list.shape,'\\n')  # debug\n",
    "print('Decoded output : ',output_matrix_list)  # debug"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-coding input [[0.31253465]\n",
      " [0.64988105]\n",
      " [0.46285792]\n",
      " [0.87116485]\n",
      " [0.16300571]\n",
      " [0.73543739]\n",
      " [0.87720381]\n",
      " [0.10481646]\n",
      " [0.25661832]\n",
      " [0.12864984]\n",
      " [0.43254218]\n",
      " [0.24213778]\n",
      " [0.47969327]\n",
      " [0.77543692]\n",
      " [0.27838596]\n",
      " [0.37542619]\n",
      " [0.34502107]\n",
      " [0.90949674]\n",
      " [0.94132232]\n",
      " [0.95462121]\n",
      " [0.25297526]\n",
      " [0.85078528]\n",
      " [0.95914518]\n",
      " [0.62267666]\n",
      " [0.27804151]\n",
      " [0.19312671]\n",
      " [0.12474689]\n",
      " [0.96147462]\n",
      " [0.22552421]\n",
      " [0.29506973]\n",
      " [0.21833016]\n",
      " [0.14108585]\n",
      " [0.75886411]\n",
      " [0.70843876]\n",
      " [0.97537786]] \n",
      "\n",
      "Dense_vae.forward input shape: (35, 1)\n",
      "Dense_vae.forward input shape: (20, 1)\n",
      "Dense_vae.forward input shape: (10, 1)\n",
      "Dense_vae.forward input shape: (35, 1)\n",
      "Dense_vae.forward input shape: (20, 1)\n",
      "Dense_vae.forward input shape: (10, 1)\n",
      "mu= [[0.21062671]\n",
      " [2.70097147]] logvar= [[ 2.03222493]\n",
      " [-0.26061233]] \n",
      "\n",
      "reparameterize input:  [[0.21062671]\n",
      " [2.70097147]] [[ 2.03222493]\n",
      " [-0.26061233]] \n",
      "\n",
      "[[6.03942696]\n",
      " [1.79861988]]\n",
      "z= [[6.03942696]\n",
      " [1.79861988]] \n",
      "\n",
      "Dense_vae.forward input shape: (2, 1)\n",
      "Dense_vae.forward input shape: (10, 1)\n",
      "Dense_vae.forward input shape: (20, 1)\n",
      "Decoded output shape:  (35, 1) \n",
      "\n",
      "Decoded output :  [[ 1.34569967e+00]\n",
      " [ 2.92216195e+00]\n",
      " [-3.22041147e-01]\n",
      " [ 2.29120936e-03]\n",
      " [-2.14226698e+00]\n",
      " [-1.04402451e+00]\n",
      " [-6.80209154e-01]\n",
      " [ 1.09615727e+00]\n",
      " [ 3.55966718e+00]\n",
      " [-1.14140890e+00]\n",
      " [-5.35122513e-02]\n",
      " [-4.19141875e+00]\n",
      " [ 1.41800070e+00]\n",
      " [ 4.91044267e+00]\n",
      " [-8.52941877e-01]\n",
      " [-3.64699861e+00]\n",
      " [ 1.99869344e+00]\n",
      " [ 2.34646566e+00]\n",
      " [-4.13511177e+00]\n",
      " [-1.74100472e+00]\n",
      " [-9.06575977e-01]\n",
      " [-6.75165469e+00]\n",
      " [ 6.81234399e-01]\n",
      " [ 5.38058787e-01]\n",
      " [ 5.40583461e-01]\n",
      " [ 2.88755464e+00]\n",
      " [ 2.08094830e+00]\n",
      " [-1.58224698e+00]\n",
      " [-5.76620204e-01]\n",
      " [ 5.11139792e+00]\n",
      " [-1.95322940e+00]\n",
      " [ 4.06593710e+00]\n",
      " [ 1.27846448e+00]\n",
      " [-4.34719677e+00]\n",
      " [ 4.10988804e+00]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
