{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T17:23:24.015768Z",
     "start_time": "2024-06-25T17:23:23.370941Z"
    }
   },
   "source": [
    "from MultiLayerPerceptron import train, Dense, predict_with_layer_value,mse, mse_derivative\n",
    "from activation_functions import Sigmoid\n",
    "from utils import *\n",
    "from plots import *\n",
    "from font import fontDict\n",
    "import numpy as np\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config params"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T17:23:24.019849Z",
     "start_time": "2024-06-25T17:23:24.016825Z"
    }
   },
   "source": [
    "learning_rate, max_epochs, bias, beta1, beta2, epsilon, optimizer, activation = get_config_params('./config_denoising.json')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T17:23:24.024438Z",
     "start_time": "2024-06-25T17:23:24.021158Z"
    }
   },
   "source": [
    "bitmapDict = fonts_to_bitmap(fontDict)\n",
    "bitmapList = list(bitmapDict.values())  \n",
    "dataset = np.reshape(bitmapList,(len(bitmapList), 35, 1))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35-20-10-2-10-20-35"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T17:23:24.031752Z",
     "start_time": "2024-06-25T17:23:24.026776Z"
    }
   },
   "source": [
    "\n",
    "autoencoder = [\n",
    "    Dense(35, 20, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(20, 10, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(10, 2, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(2, 10, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(10, 20, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(20, 35, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salt & Pepper Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T17:23:35.653636Z",
     "start_time": "2024-06-25T17:23:24.033083Z"
    }
   },
   "source": [
    "# Normal training\n",
    "error = train(autoencoder, mse, mse_derivative, dataset, dataset, epochs=max_epochs, verbose=False)\n",
    "noise_level=0.1\n",
    "noisy_dataset_test_salt = add_salt_and_pepper_noise_to_dataset(dataset, noise_level)\n"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Normal training\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m error \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmse_derivative\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m noise_level\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m\n\u001B[1;32m      4\u001B[0m noisy_dataset_test_salt \u001B[38;5;241m=\u001B[39m add_salt_and_pepper_noise_to_dataset(dataset, noise_level)\n",
      "File \u001B[0;32m~/SynologyDrive/Données-Tristan/INSA-4-INFO/ITBA/AI/sia-tp5/MultiLayerPerceptron.py:43\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(network, error_function, error_derivative, x_train, y_train, epochs, verbose)\u001B[0m\n\u001B[1;32m     40\u001B[0m     grad \u001B[38;5;241m=\u001B[39m error_derivative(y, output)\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(network):\n\u001B[0;32m---> 43\u001B[0m         grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m error \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(x_train)\n\u001B[1;32m     48\u001B[0m mse\u001B[38;5;241m.\u001B[39mappend(error)\n",
      "File \u001B[0;32m~/SynologyDrive/Données-Tristan/INSA-4-INFO/ITBA/AI/sia-tp5/MultiLayerPerceptron.py:119\u001B[0m, in \u001B[0;36mDense.backward\u001B[0;34m(self, output_derivative)\u001B[0m\n\u001B[1;32m    116\u001B[0m weights_gradient \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(output_derivative, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput\u001B[38;5;241m.\u001B[39mT)\n\u001B[1;32m    117\u001B[0m input_gradient \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights\u001B[38;5;241m.\u001B[39mT, output_derivative)\n\u001B[0;32m--> 119\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights_gradient\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtime_step\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;66;03m# self.weights -= learning_rate * weights_gradient\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlearning_rate \u001B[38;5;241m*\u001B[39m output_derivative\n",
      "File \u001B[0;32m~/SynologyDrive/Données-Tristan/INSA-4-INFO/ITBA/AI/sia-tp5/MultiLayerPerceptron.py:164\u001B[0m, in \u001B[0;36mAdamOptimizer.update\u001B[0;34m(self, gradient, time_step)\u001B[0m\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros_like(gradient)\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros_like(gradient)\n\u001B[0;32m--> 164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mm\u001B[49m \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta1) \u001B[38;5;241m*\u001B[39m gradient\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta2 \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta2) \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39msquare(gradient)\n\u001B[1;32m    167\u001B[0m mHat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta1\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtime_step)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Noisy Data Set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "characters = list(bitmapDict.keys())\n",
    "\n",
    "input_matrix_list = []\n",
    "output_matrix_list = []\n",
    "noisy_matrix_list = []\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "noise_level = 0.1\n",
    "\n",
    "for c in range(len(characters)):\n",
    "    input_bitmap = []\n",
    "    noisy_bitmap = []\n",
    "    output_bitmap = []\n",
    "\n",
    "    for i in range(len(dataset[c])):\n",
    "        input_bitmap.append(dataset[c][i][0])\n",
    "    input_bitmap_matrix = bitmap_as_matrix(input_bitmap)\n",
    "    input_matrix_list.append(input_bitmap_matrix)\n",
    "\n",
    "    for i in range(len(noisy_dataset_test_salt[c])):\n",
    "        noisy_bitmap.append(noisy_dataset_test_salt[c][i][0])\n",
    "    noisy_bitmap_matrix = bitmap_as_matrix(noisy_bitmap) \n",
    "    noisy_matrix_list.append(noisy_bitmap_matrix)   \n",
    "\n",
    "    outputs, raw_latent_space = predict_with_layer_value(autoencoder, noisy_dataset_test_salt[c], 6)\n",
    "\n",
    "\n",
    "    for output in outputs:\n",
    "        output_bitmap.append(round(abs(output[0])))\n",
    "    output_bitmap_matrix = bitmap_as_matrix(output_bitmap)\n",
    "    output_matrix_list.append(output_bitmap_matrix)\n",
    "\n",
    "\n",
    "    if compare_matrixes(input_bitmap_matrix, output_bitmap_matrix) > 32: \n",
    "        correct_predictions += 1\n",
    "\n",
    "    # plot_bitmap_matrix_with_noise(input_bitmap_matrix, noisy_bitmap_matrix, output_bitmap_matrix, characters[c])\n",
    "\n",
    "print(\"Correct Predictions: \", correct_predictions)\n",
    "print(\"Accuracy: \", correct_predictions / len(characters))\n",
    "\n",
    "plot_bitmap_matrix_2(input_matrix_list, characters, \"Originals Caracters\")\n",
    "plot_bitmap_matrix_2(noisy_matrix_list, characters, \"Noisy Caracters\")\n",
    "plot_bitmap_matrix_2(output_matrix_list, characters, \"Predicted Caracters After Training on Original Data (Salt & Pepper)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with noisy DataSet"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Training with noise\n",
    "noise_level = 0.1\n",
    "for i in range(10):\n",
    "    noisy_dataset = add_salt_and_pepper_noise_to_dataset(dataset, noise_level)\n",
    "    error = train(autoencoder, mse, mse_derivative, noisy_dataset, dataset, epochs=max_epochs, verbose=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "characters = list(bitmapDict.keys())\n",
    "\n",
    "input_matrix_list = []\n",
    "output_matrix_list = []\n",
    "noisy_matrix_list = []\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "noise_level = 0.1\n",
    "\n",
    "for c in range(len(characters)):\n",
    "    input_bitmap = []\n",
    "    noisy_bitmap = []\n",
    "    output_bitmap = []\n",
    "\n",
    "\n",
    "    for i in range(len(dataset[c])):\n",
    "        input_bitmap.append(dataset[c][i][0])\n",
    "    input_bitmap_matrix = bitmap_as_matrix(input_bitmap)\n",
    "    input_matrix_list.append(input_bitmap_matrix)\n",
    "\n",
    "    for i in range(len(noisy_dataset_test_salt[c])):\n",
    "        noisy_bitmap.append(noisy_dataset_test_salt[c][i][0])\n",
    "    noisy_bitmap_matrix = bitmap_as_matrix(noisy_bitmap) \n",
    "    noisy_matrix_list.append(noisy_bitmap_matrix)   \n",
    "\n",
    "\n",
    "    outputs, raw_latent_space = predict_with_layer_value(autoencoder, noisy_dataset_test_salt[c], 6)\n",
    "\n",
    "\n",
    "    for output in outputs:\n",
    "        output_bitmap.append(round(abs(output[0])))\n",
    "    output_bitmap_matrix = bitmap_as_matrix(output_bitmap)\n",
    "    output_matrix_list.append(output_bitmap_matrix)\n",
    "\n",
    "\n",
    "    if compare_matrixes(input_bitmap_matrix, output_bitmap_matrix) > 32:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    # plot_bitmap_matrix_with_noise(input_bitmap_matrix, noisy_bitmap_matrix, output_bitmap_matrix, characters[c])\n",
    "\n",
    "print(\"Correct Predictions: \", correct_predictions)\n",
    "print(\"Accuracy: \", correct_predictions / len(characters))\n",
    "\n",
    "plot_bitmap_matrix_2(input_matrix_list, characters, \"Originals Caracters\")\n",
    "plot_bitmap_matrix_2(noisy_matrix_list, characters, \"Noisy Caracters\")\n",
    "plot_bitmap_matrix_2(output_matrix_list, characters, \"Predicted Caracters After Training on Noisy Data (Salt & Pepper)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Training on Noisy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "autoencoder2 = [\n",
    "    Dense(35, 20, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(20, 10, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(10, 2, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(2, 10, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(10, 20, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "    Dense(20, 35, optimizer_type=optimizer, learning_rate=learning_rate),\n",
    "    Sigmoid(),\n",
    "]\n",
    "\n",
    "# Normal training\n",
    "error = train(autoencoder2, mse, mse_derivative, dataset, dataset, epochs=max_epochs, verbose=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "noise_level = 0.5\n",
    "noisy_dataset_test_delta = add_noise_to_dataset(dataset, noise_level)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "characters = list(bitmapDict.keys())\n",
    "\n",
    "input_matrix_list = []\n",
    "output_matrix_list = []\n",
    "noisy_matrix_list = []\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "for c in range(len(characters)):\n",
    "    input_bitmap = []\n",
    "    noisy_bitmap = []\n",
    "    output_bitmap = []\n",
    "\n",
    "    # dataset es una lista de listas de -listas con un solo elemento-\n",
    "    for i in range(len(dataset[c])):\n",
    "        input_bitmap.append(dataset[c][i][0])\n",
    "    input_bitmap_matrix = bitmap_as_matrix(input_bitmap)\n",
    "    input_matrix_list.append(input_bitmap_matrix)\n",
    "\n",
    "    for i in range(len(noisy_dataset[c])):\n",
    "        noisy_bitmap.append(noisy_dataset_test_delta[c][i][0])\n",
    "    noisy_bitmap_matrix = bitmap_as_matrix(noisy_bitmap) \n",
    "    noisy_matrix_list.append(noisy_bitmap_matrix)   \n",
    "\n",
    "\n",
    "    # El espacio latente es la salida de la \"capa 6\"\n",
    "    outputs, raw_latent_space = predict_with_layer_value(autoencoder2, noisy_dataset_test_delta[c], 6)\n",
    "\n",
    "\n",
    "    for output in outputs:\n",
    "        output_bitmap.append(round(abs(output[0])))\n",
    "    output_bitmap_matrix = bitmap_as_matrix(output_bitmap)\n",
    "    output_matrix_list.append(output_bitmap_matrix)\n",
    "\n",
    "\n",
    "    if compare_matrixes(input_bitmap_matrix, output_bitmap_matrix) > 32: # 32 pixeles iguales de 35\n",
    "        correct_predictions += 1\n",
    "\n",
    "    # plot_bitmap_matrix(noisy_bitmap_matrix, output_bitmap_matrix, characters[c])\n",
    "\n",
    "print(\"Correct Predictions: \", correct_predictions)\n",
    "print(\"Accuracy: \", correct_predictions / len(characters))\n",
    "\n",
    "plot_bitmap_matrix_2(input_matrix_list, characters, \"Originals Caracters\")\n",
    "plot_bitmap_matrix_2(noisy_matrix_list, characters, \"Noisy Caracters\")\n",
    "plot_bitmap_matrix_2(output_matrix_list, characters, \"Predicted Caracters\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Noisy Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Training with noise\n",
    "noise_level = 0.5\n",
    "for i in range(10):\n",
    "    print(\"Iteration: \", i)\n",
    "    noisy_dataset = add_noise_to_dataset(dataset, noise_level)\n",
    "    error = train(autoencoder2, mse, mse_derivative, noisy_dataset, dataset, epochs=max_epochs, verbose=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "characters = list(bitmapDict.keys())\n",
    "\n",
    "input_matrix_list = []\n",
    "output_matrix_list = []\n",
    "noisy_matrix_list = []\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "for c in range(len(characters)):\n",
    "    input_bitmap = []\n",
    "    noisy_bitmap = []\n",
    "    output_bitmap = []\n",
    "\n",
    "    # dataset es una lista de listas de -listas con un solo elemento-\n",
    "    for i in range(len(dataset[c])):\n",
    "        input_bitmap.append(dataset[c][i][0])\n",
    "    input_bitmap_matrix = bitmap_as_matrix(input_bitmap)\n",
    "    input_matrix_list.append(input_bitmap_matrix)\n",
    "\n",
    "    for i in range(len(noisy_dataset[c])):\n",
    "        noisy_bitmap.append(noisy_dataset_test_delta[c][i][0])\n",
    "    noisy_bitmap_matrix = bitmap_as_matrix(noisy_bitmap) \n",
    "    noisy_matrix_list.append(noisy_bitmap_matrix)   \n",
    "\n",
    "\n",
    "    # El espacio latente es la salida de la \"capa 6\"\n",
    "    outputs, raw_latent_space = predict_with_layer_value(autoencoder2, noisy_dataset_test_delta[c], 6)\n",
    "\n",
    "\n",
    "    for output in outputs:\n",
    "        output_bitmap.append(round(abs(output[0])))\n",
    "    output_bitmap_matrix = bitmap_as_matrix(output_bitmap)\n",
    "    output_matrix_list.append(output_bitmap_matrix)\n",
    "\n",
    "\n",
    "    if compare_matrixes(input_bitmap_matrix, output_bitmap_matrix) > 32: # 32 pixeles iguales de 35\n",
    "        correct_predictions += 1\n",
    "\n",
    "    # plot_bitmap_matrix(noisy_bitmap_matrix, output_bitmap_matrix, characters[c])\n",
    "print(\"After Training on Noisy Data (Delta) : \")\n",
    "print(\"Correct Predictions: \", correct_predictions)\n",
    "print(\"Accuracy: \", correct_predictions / len(characters))\n",
    "\n",
    "plot_bitmap_matrix_2(input_matrix_list, characters, \"Originals Caracters\")\n",
    "plot_bitmap_matrix_2(noisy_matrix_list, characters, \"Noisy Caracters\")\n",
    "plot_bitmap_matrix_2(output_matrix_list, characters, \"Predicted Caracters After Training on Noisy Data (Delta)\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
